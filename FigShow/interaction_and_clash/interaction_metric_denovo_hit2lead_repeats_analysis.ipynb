{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "KEEP_THRESHOLD = 0.1\n",
    "father_dir = '/home/data-house-01/cdhofficial/MolGens/MolGenBench-dev/test_interaction'\n",
    "save_fig_dir = '/home/data-house-01/cdhofficial/MolGens/MolGenBench-dev/test_interaction_fig'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def repairCSV(data_path):\n",
    "    data_sample = pd.read_csv(data_path)\n",
    "    new_columns = []\n",
    "    for residue_name,interaction in zip(data_sample.iloc[0],data_sample.iloc[1]):\n",
    "        new_columns.append(f'{residue_name}_{interaction}')\n",
    "    data_sample.columns = new_columns\n",
    "    data_sample = data_sample.drop([0,1,2])\n",
    "    data_sample = data_sample.drop('protein_interaction',axis = 1).reset_index(drop = True)\n",
    "    for column in data_sample.columns:\n",
    "        if 'Hydrophobic' in column or 'VdWContact' in column:\n",
    "            data_sample.drop(column,axis = 1,inplace = True)\n",
    "            continue\n",
    "        data_sample[column] = data_sample[column].apply(lambda x: 0 if x == 'False' else  1)\n",
    "    return data_sample\n",
    "def getInteractionMap(data_sample,keep_threshold = 0.1):\n",
    "    # KEEP_THRESHOLD = 0.1\n",
    "    interaction_ref = pd.DataFrame(data_sample.sum(axis = 0).sort_values(ascending = False)).reset_index()\n",
    "    interaction_ref.columns = ['interaction','count']\n",
    "\n",
    "    interaction_ref['FilterByThreshold'] = interaction_ref['count'].apply(lambda x: True if x > keep_threshold*len(data_sample) else False)\n",
    "    interaction_ref = interaction_ref[interaction_ref['FilterByThreshold']]\n",
    "    interaction_ref['ratio'] = interaction_ref['count']/interaction_ref['count'].sum()\n",
    "    interaction_ref_map = {}\n",
    "    for interaction,ratio in zip(interaction_ref['interaction'],interaction_ref['ratio']):\n",
    "        interaction_ref_map[interaction] = ratio\n",
    "    return interaction_ref_map\n",
    "def getInteractionScore(input_serise,interaction_ref_map):\n",
    "    interaction_score = 0\n",
    "    for col_name,interaction in zip(input_serise.index,input_serise):\n",
    "        if interaction == 1 and col_name in interaction_ref_map:\n",
    "            interaction_score += interaction_ref_map[col_name]\n",
    "    \n",
    "    return interaction_score\n",
    "\n",
    "def getInteractionNum(input_serise,interaction_ref_map):\n",
    "    interaction_num = 0\n",
    "    for col_name,interaction in zip(input_serise.index,input_serise):\n",
    "        if interaction == 1 and col_name in interaction_ref_map:\n",
    "            interaction_num += 1\n",
    "    \n",
    "    return interaction_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pbar = tqdm(os.listdir(father_dir),total = len(os.listdir(father_dir)))\n",
    "error_list =[]\n",
    "for uniprot_id in pbar:\n",
    "    for type_name in ['vina_docked']:\n",
    "        pbar.set_description(desc=f\"Processing Uniprot ID: {uniprot_id}, Type: {type_name}\")\n",
    "        \n",
    "        uniprot_dir = os.path.join(father_dir,uniprot_id)\n",
    "        ref_csv_path = os.path.join(f'{father_dir}/{uniprot_id}/reference_active_molecules/{uniprot_id}_reference_active_molecules_{type_name}_interactions.csv')\n",
    "        if not os.path.exists(ref_csv_path):\n",
    "            print(f'Uniprot : {uniprot_id} dont have ref csv file')\n",
    "            continue\n",
    "        \n",
    "        data_sample = repairCSV(ref_csv_path)\n",
    "        interaction_ref_map = getInteractionMap(data_sample,keep_threshold = KEEP_THRESHOLD)\n",
    "        if not os.path.exists(ref_csv_path.replace('.csv','_score.csv')):\n",
    "                        # continue\n",
    "            data_sample['InteractionScore'] = data_sample.apply(lambda x: getInteractionScore(x, interaction_ref_map), axis=1)\n",
    "            data_sample['InteractionNum'] = data_sample.apply(lambda x: getInteractionNum(x, interaction_ref_map), axis=1)\n",
    "            data_sample = data_sample.sort_values('InteractionScore',ascending = False)\n",
    "            data_sample.to_csv(ref_csv_path.replace('.csv','_score.csv'),index = False)\n",
    "        \n",
    "        sub_dir_names = ['Round1','Round2','Round3']\n",
    "\n",
    "        for sub_dir in sub_dir_names:\n",
    "\n",
    "            \n",
    "            all_files  = glob(os.path.join(father_dir,uniprot_id,sub_dir,'*','*','*',f'*{type_name}_interactions.csv')) + \\\n",
    "                            glob(os.path.join(father_dir,uniprot_id,sub_dir,'*','*',f'*{type_name}_interactions.csv'))\n",
    "            for test_path in all_files:\n",
    "                try:\n",
    "                    if os.path.exists(test_path.replace('.csv','_score.csv')):\n",
    "                        continue\n",
    "                    test_samples = repairCSV(test_path)\n",
    "                    \n",
    "                    test_samples['InteractionScore'] = test_samples.apply(lambda x: getInteractionScore(x, interaction_ref_map), axis=1)\n",
    "                    test_samples['InteractionNum'] = test_samples.apply(lambda x: getInteractionNum(x, interaction_ref_map), axis=1)\n",
    "                    test_samples = test_samples.sort_values('InteractionScore',ascending = False)\n",
    "                    test_samples.to_csv(test_path.replace('.csv','_score.csv'),index = False)\n",
    "                except:\n",
    "                    error_list.append(test_path)\n",
    "                    continue\n",
    "\n",
    "\n",
    "            all_files  = glob(os.path.join(father_dir,uniprot_id,sub_dir,'*','*','*',f'*_interactions.csv')) + \\\n",
    "                            glob(os.path.join(father_dir,uniprot_id,sub_dir,'*','*',f'*_interactions.csv'))\n",
    "            for test_path in all_files:\n",
    "                try:\n",
    "                    if 'ligprep_glide_sp_pv' in os.path.basename(test_path) or 'vina_docked' in os.path.basename(test_path):\n",
    "                        continue\n",
    "                    \n",
    "                    if os.path.exists(test_path.replace('.csv',f'_score_raw_compare_{type_name}.csv')):\n",
    "                        continue\n",
    "                    test_samples = repairCSV(test_path)\n",
    "                    test_samples['InteractionScore'] = test_samples.apply(lambda x: getInteractionScore(x, interaction_ref_map), axis=1)\n",
    "                    test_samples['InteractionNum'] = test_samples.apply(lambda x: getInteractionNum(x, interaction_ref_map), axis=1)\n",
    "                    test_samples = test_samples.sort_values('InteractionScore',ascending = False)\n",
    "                    test_samples.to_csv(test_path.replace('.csv',f'_score_raw_compare_{type_name}.csv'),index = False)\n",
    "                except:\n",
    "                    error_list.append(test_path)\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计不同的模型的interactionscore 的累积分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to read the csv files in all folders, and then add a filename column to each file\n",
    "def read_csv_files_in_directory(directory):\n",
    "\n",
    "    all_dataframes = []\n",
    "    sub_dir_names = ['Round1','Round2','Round3','reference_active_molecules']\n",
    "    for uniprot_id in os.listdir(directory):\n",
    "        for sub_dir in sub_dir_names:\n",
    "\n",
    "            if sub_dir == 'reference_active_molecules':\n",
    "                csv_files  = glob(os.path.join(directory,uniprot_id,sub_dir,f'*score*.csv'))\n",
    "            else:\n",
    "                    \n",
    "                csv_files  = glob(os.path.join(directory,uniprot_id,sub_dir,'*','*','*',f'*score*.csv')) + \\\n",
    "                                glob(os.path.join(directory,uniprot_id,sub_dir,'*','*',f'*score*.csv'))\n",
    "\n",
    "            for file in csv_files:\n",
    "\n",
    "                df = pd.read_csv(file)\n",
    "\n",
    "                df['filename'] = [file]*len(df)\n",
    "                df['uniprot_id'] = [uniprot_id]*len(df)\n",
    "                df['round'] = [sub_dir]*len(df)\n",
    "\n",
    "                if sub_dir == 'reference_active_molecules':\n",
    "                    df['model_name'] = 'Reference'\n",
    "                    df['Task'] = ['Reference']*len(df)\n",
    "                else:\n",
    "                    if 'Sries' not in file:\n",
    "                        df['model_name'] = df['filename'].apply(lambda x: '_'.join(os.path.basename(x).split('_generated')[0].split('_')[1:]))\n",
    "                        df['Task'] = ['Denovo']*len(df)\n",
    "                    else:\n",
    "                        df['model_name'] = df['filename'].apply(lambda x: '_'.join(os.path.basename(x).split('_Hit')[0].split('_')[2:]))\n",
    "                        df['Task'] = ['Hit2Lead']*len(df)\n",
    "                df = df[['Task','model_name','round','uniprot_id','filename','InteractionScore','InteractionNum']]\n",
    "                \n",
    "                all_dataframes.append(df)\n",
    "                \n",
    "        \n",
    "\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "combined_df = read_csv_files_in_directory(father_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_func_interaction_type(filename):\n",
    "    type_name = 'Glide' if 'glide' in filename else 'Vina'\n",
    "    type_name = type_name if 'raw_compare' not in filename else 'Raw_Compare_' + type_name\n",
    "    return type_name\n",
    "combined_df['interaction_type'] = combined_df['filename'].apply(lambda x: temp_func_interaction_type(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['interaction_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the values of different quantiles of the reference, and then calculate the proportion greater than this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df_denovo_round1['interaction_type'].unique()\n",
    "def calculate_quantile_proportions(reference_df, generated_df, quantiles=[0.25, 0.5, 0.75]):\n",
    "    \"\"\"\n",
    "    Calculates the proportion of generated molecules with InteractionScores exceeding \n",
    "    reference quantiles for each interaction type, uniprot_id, and model.\n",
    "\n",
    "    Args:\n",
    "        reference_df (pd.DataFrame): DataFrame with reference interaction scores.\n",
    "        generated_df (pd.DataFrame): DataFrame with generated molecules' interaction scores.\n",
    "        quantiles (list): A list of quantiles to calculate (e.g., [0.25, 0.5, 0.75]).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the calculated proportions.\n",
    "    \"\"\"\n",
    "    # Calculate quantile thresholds from the reference dataframe\n",
    "    thresholds = reference_df.groupby(['interaction_type', 'uniprot_id'])['InteractionScore'].quantile(quantiles).unstack()\n",
    "    # Duplicate Vina thresholds and rename as Raw_Compare_Vina\n",
    "    if 'Vina' in thresholds.index.get_level_values('interaction_type'):\n",
    "        vina_dup = thresholds.xs('Vina', level='interaction_type', drop_level=False).copy()\n",
    "        vina_dup.index = pd.MultiIndex.from_tuples(\n",
    "            [('Raw_Compare_Vina', uid) for _, uid in vina_dup.index],\n",
    "            names=thresholds.index.names\n",
    "        )\n",
    "        thresholds = pd.concat([thresholds, vina_dup])\n",
    "    if 'Glide' in thresholds.index.get_level_values('interaction_type'):\n",
    "        vina_dup = thresholds.xs('Glide', level='interaction_type', drop_level=False).copy()\n",
    "        vina_dup.index = pd.MultiIndex.from_tuples(\n",
    "            [('Raw_Compare_Glide', uid) for _, uid in vina_dup.index],\n",
    "            names=thresholds.index.names\n",
    "        )\n",
    "        thresholds = pd.concat([thresholds, vina_dup])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Group the generated data to calculate proportions\n",
    "    grouped_generated = generated_df.groupby(['interaction_type', 'uniprot_id', 'model_name'])\n",
    "    \n",
    "    for name, group in grouped_generated:\n",
    "        interaction_type, uniprot_id, model_name = name\n",
    "        \n",
    "        # Check if the corresponding threshold exists\n",
    "        if (interaction_type, uniprot_id) in thresholds.index:\n",
    "            threshold_values = thresholds.loc[(interaction_type, uniprot_id)]\n",
    "            total_count = len(group)\n",
    "            \n",
    "            if total_count > 0:\n",
    "                for quantile_level, threshold in threshold_values.items():\n",
    "                    # Count how many scores are above the threshold\n",
    "                    count_above = (group['InteractionScore'] > threshold).sum()\n",
    "                    proportion = count_above / total_count\n",
    "                    \n",
    "                    results.append({\n",
    "                        'interaction_type': interaction_type,\n",
    "                        'uniprot_id': uniprot_id,\n",
    "                        'model_name': model_name,\n",
    "                        'quantile': quantile_level,\n",
    "                        'proportion_above': proportion\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def replace_model_name(model_name):\n",
    "    if 'diffSBDD_cond_crossdocked' in model_name:\n",
    "        return 'DiffSBDD-C'\n",
    "    elif 'diffSBDD_cond_moad' in model_name:\n",
    "        return 'DiffSBDD-M'\n",
    "    elif 'shepherd' in model_name:\n",
    "        return 'ShEPhERD'\n",
    "    elif 'DeleteHit2Lead' in model_name:\n",
    "        return 'Delete'\n",
    "    else:\n",
    "        return model_name\n",
    "\n",
    "def plot_quantile_polar(stats_df, interaction_type, quantiles=(0.25, 0.50, 0.75),\n",
    "                        quantile_palette=None, model_order=None, show_mean_values=True, show_legend=True,\n",
    "                        title_suffix=\"R=mean±std(ALL Proteins)\"):\n",
    "    \"\"\"\n",
    "    Aggregate all uniprot, display each model's proportion_above_mean for different quantiles in polar coordinates\n",
    "    (radius = mean, shading = ± std average).\n",
    "    \"\"\"\n",
    "    from matplotlib.patches import Patch  # Import only for creating legend color patches\n",
    "    sub_df = stats_df[stats_df['interaction_type'] == interaction_type].copy()  # Filter data for specified interaction\n",
    "    agg = (sub_df\n",
    "           .groupby(['model_name', 'quantile'], as_index=False)  # Aggregate by model and quantile\n",
    "           .agg({'proportion_above_mean': 'mean',                # Calculate mean of mean (across uniprot / repeat)\n",
    "                 'proportion_above_std': 'mean'}))               # Calculate mean of std (across uniprot / repeat)\n",
    "\n",
    "    quantiles = list(quantiles)  # Ensure quantiles are indexable\n",
    "    if model_order is None:  # If model order is not specified\n",
    "        first_q = quantiles[0]  # Use first quantile for sorting\n",
    "        model_order = (agg[agg['quantile'] == first_q]  # Get rows for this quantile\n",
    "                       .sort_values('proportion_above_mean', ascending=False)  # Sort by mean descending\n",
    "                       ['model_name'].tolist())  # Extract model order list\n",
    "\n",
    "    n_models = len(model_order)  # Number of models\n",
    "    sector_width = 2 * np.pi / max(n_models, 1)  # Radian width of each sector\n",
    "\n",
    "    if quantile_palette is None:  # If quantile colors not specified\n",
    "        quantile_palette = {q: c for q, c in zip(quantiles, sns.color_palette('hls', len(quantiles)))}  # Auto-assign colors\n",
    "\n",
    "    base_palette = sns.color_palette('deep', n_models)  # Generate base colors for each model\n",
    "    model_sorted = sorted(model_order)  # Sort model names (ensure color mapping stable)\n",
    "    base_color = dict(zip(model_sorted, base_palette))   # Map model->color\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'polar': True})  # Create polar plot\n",
    "    ax.set_xticks([])            # Remove polar angle ticks\n",
    "    ax.set_rlim(0, 1.0)          # Fixed radius range 0~1\n",
    "    # ax.set_rticks([0.25, 0.5, 0.75, 1.0])  # No need to display radius ticks\n",
    "    # Display radius tick lines but not tick values\n",
    "    ax.set_rticks([0.25, 0.5, 0.75, 1.0])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_rlabel_position(90)   # Place radius labels at 90°\n",
    "    ax.grid(alpha=1, linestyle=':', linewidth=1.5)  # Grid style\n",
    "\n",
    "    # Draw background sectors (one base color扇形 for each model)\n",
    "    for idx, model in enumerate(model_order):\n",
    "        theta_mid = (idx + 0.5) * sector_width  # Sector center angle\n",
    "        ax.bar(theta_mid, 1.0, width=sector_width, bottom=0,  # Use bar to generate扇形\n",
    "               color=base_color[model], edgecolor='none',\n",
    "               linewidth=0, alpha=0.25, zorder=0)\n",
    "\n",
    "    theta_res = 80  # Number of interpolation points per sector curve\n",
    "    for idx, model in enumerate(model_order):  # Iterate through models\n",
    "        theta_start = idx * sector_width       # Sector start angle\n",
    "        theta_end = (idx + 1) * sector_width   # Sector end angle\n",
    "        theta = np.linspace(theta_start, theta_end, theta_res)  # Angle sampling\n",
    "\n",
    "        for q in quantiles:  # Iterate through each quantile\n",
    "            row = agg[(agg['model_name'] == model) & (agg['quantile'] == q)]  # Get aggregated row for this model and quantile\n",
    "            if row.empty:\n",
    "                continue  # Skip if missing\n",
    "            mean_r = float(row['proportion_above_mean'])  # Radius mean\n",
    "            std_r = float(row['proportion_above_std'])    # Radius std (average std)\n",
    "            mean_r = np.clip(mean_r, 0, 1)                # Clip mean to [0,1]\n",
    "            std_r = max(std_r, 0)                         # Ensure non-negative\n",
    "\n",
    "            lower = max(mean_r - std_r, 0.0)  # Shading lower bound\n",
    "            upper = min(mean_r + std_r, 1.0)  # Shading upper bound\n",
    "\n",
    "            if std_r > 0:\n",
    "                ax.fill_between(theta, lower, upper,       # Draw ±std shading\n",
    "                                color=quantile_palette[q],\n",
    "                                alpha=0.4, linewidth=0, zorder=2)\n",
    "\n",
    "            ax.plot(theta,\n",
    "                    np.full_like(theta, mean_r),           # Draw mean arc\n",
    "                    color=quantile_palette[q],\n",
    "                    linewidth=1.5,\n",
    "                    label=f\"Q{int(q*100)}\" if (idx == 0) else None,  # Only add legend label for first sector\n",
    "                    zorder=3)\n",
    "\n",
    "        ax.plot([theta_start, theta_start], [0, 1.0],       # Sector left boundary\n",
    "                color='gray', linewidth=0.6, alpha=0.6, zorder=5)\n",
    "        # Add average value labels for each quantile of this model (separated from mean line, placed above or below)\n",
    "        \n",
    "        if show_mean_values:\n",
    "            theta_mid = (theta_start + theta_end) / 2\n",
    "            for q in quantiles:\n",
    "                row_q = agg[(agg['model_name'] == model) & (agg['quantile'] == q)]\n",
    "                if row_q.empty:\n",
    "                    continue\n",
    "                m_val = float(row_q['proportion_above_mean'])\n",
    "                label_r = min(m_val + 0.05, 0.98)\n",
    "                if label_r - m_val < 0.03:  # If truncated, place below\n",
    "                    label_r = max(m_val - 0.05, 0.02)\n",
    "                ax.text(theta_mid, label_r, f\"{m_val:.3f}\",\n",
    "                    ha='center', va='center',\n",
    "                    fontsize=7, color=quantile_palette[q])\n",
    "\n",
    "    ax.plot([n_models * sector_width, n_models * sector_width], [0, 1.0],  # Rightmost boundary line (close)\n",
    "            color='gray', linewidth=0.6, alpha=0.6, zorder=5)\n",
    "\n",
    "    ax.set_title(f\"{interaction_type} | {title_suffix}\", pad=30, fontsize=12)  # Title\n",
    "    \n",
    "    model_patches = [Patch(facecolor=base_color[m], alpha=0.4, label=replace_model_name(m)) for m in model_order]  # Model legend color patches\n",
    "    if show_legend:\n",
    "        # First make space for right-side model legend to avoid cropping\n",
    "        fig.subplots_adjust(right=0.80)\n",
    "\n",
    "        # Place quantile legend inside the plot (no longer outside right), avoid half going out\n",
    "        q_legend = ax.legend(loc='center left',\n",
    "                     bbox_to_anchor=(1.05, 0.8),\n",
    "                     frameon=False,\n",
    "                     title='Quantiles',\n",
    "                     ncol=1,\n",
    "                     handlelength=1.2,\n",
    "                     columnspacing=1.0)\n",
    "        ax.add_artist(q_legend)  # Add quantile legend\n",
    "\n",
    "        ax.legend(handles=model_patches, loc='center left',   # Model legend\n",
    "                bbox_to_anchor=(1.05, 0.5),\n",
    "                frameon=False, title='Models')\n",
    "\n",
    "    plt.tight_layout()  # Compact layout\n",
    "    # Solve legend cropping: shrink polar area, leave space for right legend\n",
    "    os.makedirs(save_fig_dir, exist_ok=True)\n",
    "    plt.savefig(f'{save_fig_dir}/polar_plot_{interaction_type}_{title_suffix}.svg', bbox_inches='tight', dpi=660, format='svg')  # Save image\n",
    "\n",
    "    return \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "with open('../../sup_info/UniprotIDs_duplicated_with_crossdock2020.json','r') as f:\n",
    "    UniprotId_in_crossdock = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_hit2lead = combined_df[combined_df['Task'] == 'Hit2Lead']\n",
    "combined_df_denovo = combined_df[combined_df['Task'] == 'Denovo']\n",
    "combined_df_reference = combined_df[combined_df['Task'] == 'Reference']\n",
    "# Denovo \n",
    "combined_df_denovo_round1 = combined_df_denovo[combined_df_denovo['round'] == 'Round1']\n",
    "combined_df_denovo_round2 = combined_df_denovo[combined_df_denovo['round'] == 'Round3']\n",
    "combined_df_denovo_round3 = combined_df_denovo[combined_df_denovo['round'] == 'Round3']\n",
    "# hit2lead \n",
    "combined_df_hit2lead_round1 = combined_df_hit2lead[combined_df_hit2lead['round'] == 'Round1']\n",
    "combined_df_hit2lead_round2 = combined_df_hit2lead[combined_df_hit2lead['round'] == 'Round3']\n",
    "combined_df_hit2lead_round3 = combined_df_hit2lead[combined_df_hit2lead['round'] == 'Round3'] \n",
    "\n",
    "## unseen proteins\n",
    "combined_df_unseen = combined_df[~combined_df['uniprot_id'].isin(UniprotId_in_crossdock.keys())]\n",
    "combined_df_seen = combined_df[combined_df['uniprot_id'].isin(UniprotId_in_crossdock.keys())]\n",
    "print(f\"unseen proteins:{len(combined_df_unseen['uniprot_id'].unique())}\",f\"seen proteins:{len(combined_df_seen['uniprot_id'].unique())}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_hit2lead_unseen = combined_df_unseen [combined_df_unseen ['Task'] == 'Hit2Lead']\n",
    "combined_df_denovo_unseen = combined_df_unseen [combined_df_unseen ['Task'] == 'Denovo']\n",
    "combined_df_reference_unseen = combined_df_unseen [combined_df_unseen ['Task'] == 'Reference']\n",
    "# unseen denovo proteins \n",
    "combined_df_unseen_denovo_round1 = combined_df_denovo_unseen[combined_df_denovo_unseen['round'] == 'Round1']\n",
    "combined_df_unseen_denovo_round2 =combined_df_denovo_unseen[combined_df_denovo_unseen['round'] == 'Round2']\n",
    "combined_df_unseen_denovo_round3 = combined_df_denovo_unseen[combined_df_denovo_unseen['round'] == 'Round3']\n",
    "#unseen hit2lead proteins \n",
    "combined_df_unseen_hit2lead_round1 = combined_df_hit2lead_unseen[combined_df_hit2lead_unseen['round'] == 'Round1']\n",
    "combined_df_unseen_hit2lead_round2 = combined_df_hit2lead_unseen[combined_df_hit2lead_unseen['round'] == 'Round2']        \n",
    "combined_df_unseen_hit2lead_round3 = combined_df_hit2lead_unseen[combined_df_hit2lead_unseen['round'] == 'Round3']\n",
    "\n",
    "\n",
    "## seen proteins\n",
    "\n",
    "combined_df_hit2lead_seen = combined_df_seen [combined_df_seen ['Task'] == 'Hit2Lead']\n",
    "combined_df_denovo_seen = combined_df_seen [combined_df_seen ['Task'] == 'Denovo']\n",
    "combined_df_reference_seen = combined_df_seen [combined_df_seen ['Task'] == 'Reference']\n",
    "# seen denovo proteins 结\n",
    "combined_df_seen_denovo_round1 = combined_df_denovo_seen[combined_df_denovo_seen['round'] == 'Round1']\n",
    "combined_df_seen_denovo_round2 = combined_df_denovo_seen[combined_df_denovo_seen['round'] == 'Round2']\n",
    "combined_df_seen_denovo_round3 = combined_df_denovo_seen[combined_df_denovo_seen['round'] == 'Round3']\n",
    "# seen hit2lead proteins \n",
    "combined_df_seen_hit2lead_round1 = combined_df_hit2lead_seen[combined_df_hit2lead_seen['round'] == 'Round1']\n",
    "combined_df_seen_hit2lead_round2 = combined_df_hit2lead_seen[combined_df_hit2lead_seen['round'] == 'Round2']        \n",
    "combined_df_seen_hit2lead_round3 = combined_df_hit2lead_seen[combined_df_hit2lead_seen['round'] == 'Round3']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all denovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## denovo all proteins\n",
    "denovo_proportions_round1 = calculate_quantile_proportions(combined_df_reference, combined_df_denovo_round1)\n",
    "denovo_proportions_round2 = calculate_quantile_proportions(combined_df_reference, combined_df_denovo_round2)\n",
    "denovo_proportions_round3 = calculate_quantile_proportions(combined_df_reference, combined_df_denovo_round3)\n",
    "\n",
    "denovo_proportions_round1['repeat'] = 'Round1'\n",
    "denovo_proportions_round2['repeat'] = 'Round2'\n",
    "denovo_proportions_round3['repeat'] = 'Round3'\n",
    "# merge all rounds\n",
    "denovo_proportions_all = pd.concat(\n",
    "    [denovo_proportions_round1, denovo_proportions_round2, denovo_proportions_round3],\n",
    "    ignore_index=True\n",
    ")\n",
    "# compute mean and std\n",
    "denovo_proportions_stats = (\n",
    "    denovo_proportions_all\n",
    "    .groupby(['interaction_type', 'uniprot_id', 'model_name', 'quantile'])['proportion_above']\n",
    "    .agg(['mean', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'proportion_above_mean',\n",
    "                     'std': 'proportion_above_std',\n",
    "                     'count': 'n_repeats'})\n",
    ")\n",
    "for target_interaction in denovo_proportions_stats['interaction_type'].unique():\n",
    "    plot_quantile_polar(denovo_proportions_stats , target_interaction,title_suffix='R=Mean±Std(All Proteins Denovo)_with_legend_mean_value',show_mean_values = True,show_legend=True)\n",
    "    plot_quantile_polar(denovo_proportions_stats , target_interaction,title_suffix='R=Mean±Std(All Proteins Denovo)',show_mean_values = False,show_legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seen denovo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## seen_denovo all proteins\n",
    "\n",
    "seen_denovo_proportions_round1 = calculate_quantile_proportions(combined_df_reference, combined_df_seen_denovo_round1)\n",
    "seen_denovo_proportions_round2 = calculate_quantile_proportions(combined_df_reference, combined_df_seen_denovo_round2)\n",
    "seen_denovo_proportions_round3 = calculate_quantile_proportions(combined_df_reference, combined_df_seen_denovo_round3)\n",
    "\n",
    "seen_denovo_proportions_round1['repeat'] = 'Round1'\n",
    "seen_denovo_proportions_round2['repeat'] = 'Round2'\n",
    "seen_denovo_proportions_round3['repeat'] = 'Round3'\n",
    "# merge all rounds\n",
    "seen_denovo_proportions_all = pd.concat(\n",
    "    [seen_denovo_proportions_round1, seen_denovo_proportions_round2, seen_denovo_proportions_round3],\n",
    "    ignore_index=True\n",
    ")\n",
    "# compute mean and std\n",
    "seen_denovo_proportions_stats = (\n",
    "    seen_denovo_proportions_all\n",
    "    .groupby(['interaction_type', 'uniprot_id', 'model_name', 'quantile'])['proportion_above']\n",
    "    .agg(['mean', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'proportion_above_mean',\n",
    "                     'std': 'proportion_above_std',\n",
    "                     'count': 'n_repeats'})\n",
    ")\n",
    "for target_interaction in seen_denovo_proportions_stats['interaction_type'].unique():\n",
    "    plot_quantile_polar(seen_denovo_proportions_stats , target_interaction,title_suffix='R=Mean±Std(seen Proteins denovo)_with_legend_mean_value',show_mean_values = True,show_legend=True)\n",
    "    plot_quantile_polar(seen_denovo_proportions_stats , target_interaction,title_suffix='R=Mean±Std(seen Proteins denovo)',show_mean_values = False,show_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unseen denovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## unseen_denovo all proteins\n",
    "\n",
    "unseen_denovo_proportions_round1 = calculate_quantile_proportions(combined_df_reference, combined_df_unseen_denovo_round1)\n",
    "unseen_denovo_proportions_round2 = calculate_quantile_proportions(combined_df_reference, combined_df_unseen_denovo_round2)\n",
    "unseen_denovo_proportions_round3 = calculate_quantile_proportions(combined_df_reference, combined_df_unseen_denovo_round3)\n",
    "\n",
    "unseen_denovo_proportions_round1['repeat'] = 'Round1'\n",
    "unseen_denovo_proportions_round2['repeat'] = 'Round2'\n",
    "unseen_denovo_proportions_round3['repeat'] = 'Round3'\n",
    "# merge all rounds\n",
    "unseen_denovo_proportions_all = pd.concat(\n",
    "    [unseen_denovo_proportions_round1, unseen_denovo_proportions_round2, unseen_denovo_proportions_round3],\n",
    "    ignore_index=True\n",
    ")\n",
    "# compute mean and std\n",
    "unseen_denovo_proportions_stats = (\n",
    "    unseen_denovo_proportions_all\n",
    "    .groupby(['interaction_type', 'uniprot_id', 'model_name', 'quantile'])['proportion_above']\n",
    "    .agg(['mean', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'proportion_above_mean',\n",
    "                     'std': 'proportion_above_std',\n",
    "                     'count': 'n_repeats'})\n",
    ")\n",
    "for target_interaction in unseen_denovo_proportions_stats['interaction_type'].unique():\n",
    "    plot_quantile_polar(unseen_denovo_proportions_stats , target_interaction,title_suffix='R=Mean±Std(unseen Proteins denovo)_with_legend_mean_value',show_mean_values = True,show_legend=True)\n",
    "    plot_quantile_polar(unseen_denovo_proportions_stats , target_interaction,title_suffix='R=Mean±Std(unseen Proteins denovo)',show_mean_values = False,show_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unseen hit2lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## unseen_hit2lead all proteins\n",
    "# combined_df_unseen_unseen_hit2lead_round2 \n",
    "unseen_hit2lead_proportions_round1 = calculate_quantile_proportions(combined_df_reference, combined_df_unseen_hit2lead_round1)\n",
    "unseen_hit2lead_proportions_round2 = calculate_quantile_proportions(combined_df_reference, combined_df_unseen_hit2lead_round2)\n",
    "unseen_hit2lead_proportions_round3 = calculate_quantile_proportions(combined_df_reference, combined_df_unseen_hit2lead_round3)\n",
    "\n",
    "unseen_hit2lead_proportions_round1['repeat'] = 'Round1'\n",
    "unseen_hit2lead_proportions_round2['repeat'] = 'Round2'\n",
    "unseen_hit2lead_proportions_round3['repeat'] = 'Round3'\n",
    "# merge all rounds\n",
    "unseen_hit2lead_proportions_all = pd.concat(\n",
    "    [unseen_hit2lead_proportions_round1, unseen_hit2lead_proportions_round2, unseen_hit2lead_proportions_round3],\n",
    "    ignore_index=True\n",
    ")\n",
    "# compute mean and std\n",
    "unseen_hit2lead_proportions_stats = (\n",
    "    unseen_hit2lead_proportions_all\n",
    "    .groupby(['interaction_type', 'uniprot_id', 'model_name', 'quantile'])['proportion_above']\n",
    "    .agg(['mean', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'proportion_above_mean',\n",
    "                     'std': 'proportion_above_std',\n",
    "                     'count': 'n_repeats'})\n",
    ")\n",
    "for target_interaction in unseen_hit2lead_proportions_stats['interaction_type'].unique():\n",
    "    plot_quantile_polar(unseen_hit2lead_proportions_stats , target_interaction,title_suffix='R=Mean±Std(unseen Proteins hit2lead)_with_legend_mean_value',show_mean_values = True,show_legend=True)\n",
    "    plot_quantile_polar(unseen_hit2lead_proportions_stats , target_interaction,title_suffix='R=Mean±Std(unseen Proteins hit2lead)',show_mean_values = False,show_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seen hit2lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## seen_hit2lead all proteins\n",
    "# combined_df_seen_seen_hit2lead_round2 \n",
    "seen_hit2lead_proportions_round1 = calculate_quantile_proportions(combined_df_reference, combined_df_seen_hit2lead_round1)\n",
    "seen_hit2lead_proportions_round2 = calculate_quantile_proportions(combined_df_reference, combined_df_seen_hit2lead_round2)\n",
    "seen_hit2lead_proportions_round3 = calculate_quantile_proportions(combined_df_reference, combined_df_seen_hit2lead_round3)\n",
    "\n",
    "seen_hit2lead_proportions_round1['repeat'] = 'Round1'\n",
    "seen_hit2lead_proportions_round2['repeat'] = 'Round2'\n",
    "seen_hit2lead_proportions_round3['repeat'] = 'Round3'\n",
    "# merge all rounds\n",
    "seen_hit2lead_proportions_all = pd.concat(\n",
    "    [seen_hit2lead_proportions_round1, seen_hit2lead_proportions_round2, seen_hit2lead_proportions_round3],\n",
    "    ignore_index=True\n",
    ")\n",
    "# compute mean and std\n",
    "seen_hit2lead_proportions_stats = (\n",
    "    seen_hit2lead_proportions_all\n",
    "    .groupby(['interaction_type', 'uniprot_id', 'model_name', 'quantile'])['proportion_above']\n",
    "    .agg(['mean', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'proportion_above_mean',\n",
    "                     'std': 'proportion_above_std',\n",
    "                     'count': 'n_repeats'})\n",
    ")\n",
    "for target_interaction in seen_hit2lead_proportions_stats['interaction_type'].unique():\n",
    "    plot_quantile_polar(seen_hit2lead_proportions_stats , target_interaction,title_suffix='R=Mean±Std(seen Proteins hit2lead)_with_legend_mean_value',show_mean_values = True,show_legend=True)\n",
    "    plot_quantile_polar(seen_hit2lead_proportions_stats , target_interaction,title_suffix='R=Mean±Std(seen Proteins hit2lead)',show_mean_values = False,show_legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all hit2lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## hit2lead all proteins\n",
    "hit2lead_proportions_round1 = calculate_quantile_proportions(combined_df_reference, combined_df_hit2lead_round1)\n",
    "hit2lead_proportions_round2 = calculate_quantile_proportions(combined_df_reference, combined_df_hit2lead_round2)\n",
    "hit2lead_proportions_round3 = calculate_quantile_proportions(combined_df_reference, combined_df_hit2lead_round3)\n",
    "\n",
    "hit2lead_proportions_round1['repeat'] = 'Round1'\n",
    "hit2lead_proportions_round2['repeat'] = 'Round2'\n",
    "hit2lead_proportions_round3['repeat'] = 'Round3'\n",
    "# merge all rounds\n",
    "hit2lead_proportions_all = pd.concat(\n",
    "    [hit2lead_proportions_round1, hit2lead_proportions_round2, hit2lead_proportions_round3],\n",
    "    ignore_index=True\n",
    ")\n",
    "# compute mean and std\n",
    "hit2lead_proportions_stats = (\n",
    "    hit2lead_proportions_all\n",
    "    .groupby(['interaction_type', 'uniprot_id', 'model_name', 'quantile'])['proportion_above']\n",
    "    .agg(['mean', 'std', 'count'])\n",
    "    .reset_index()\n",
    "    .rename(columns={'mean': 'proportion_above_mean',\n",
    "                     'std': 'proportion_above_std',\n",
    "                     'count': 'n_repeats'})\n",
    ")\n",
    "for target_interaction in hit2lead_proportions_stats['interaction_type'].unique():\n",
    "    plot_quantile_polar(hit2lead_proportions_stats , target_interaction,title_suffix='R=Mean±Std(All Proteins hit2lead)_with_legend_mean_value',show_mean_values = True,show_legend=True)\n",
    "    plot_quantile_polar(hit2lead_proportions_stats , target_interaction,title_suffix='R=Mean±Std(All Proteins hit2lead)',show_mean_values = False,show_legend=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MolGenBench",
   "language": "python",
   "name": "molgenbench"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
